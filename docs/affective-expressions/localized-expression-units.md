---
layout:
  width: default
  title:
    visible: false
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
  metadata:
    visible: false
---

# Facial Expressions

<h2 align="center">Facial Expressions</h2>

Facial expressions are a key aspect of facial behavior, closely linked to social and emotional processes and influenced by mental health, mood, and personality. These expressions serve both emotional and communicative functions and can be either spontaneous or deliberate. Bitbox offers multiple data types and methods to capture, measure, and analyze facial expressions effectively.

### Facial Landmark Points

Facial landmarks are a set of points on the face that correspond to features, such as brows, eyes, noise, mouth. By tracking these points throughout a video, we can quantify the facial expressions and behavior at each frame, as the facial features correspond to parts of the face that move with facial expressions.&#x20;

Most facial analysis processors (_e.g._, OpenFace) only provides landmarks in 2D space, which is known to be affected by head pose and facial morphology. Processors 3DI and 3DI-lite, however, provide facial landmarks both in 2D and in 3D. The latter include a variant called canonicalized 3D landmarks, which are particularly useful for the analysis of expressions, as they remove the effect of head movements, which often occur in naturalistic videos. Also, canonicalized 3D landmarks eliminate the effect of person-specific facial morphology, which is also advantageous for expression analysis, as certain personal characteristics (_e.g._, lower-than-usual eyebrows, wider-than-usual mouth) can be mistaken by algorithms are expression-related facial deformations. Both 3DI and 3DI-lite use the iBUG-51 landmark template, which tracks the brows, eyes, nose and mouth with 51 landmarks. See [output formats](../overview/outputs.md#id-2d-face-landmarks) for more details.

```python
from bitbox.face_backend import FaceProcessor3DI as FP
processor = FP()
...
# detect 2D landmarks
lands2D = processor.detect_landmarks()

# detect 3D landmarks
exp_global, pose, lands3D = processor.fit()
```

Landmarks can be used to compute [biomechanical properties](broken-reference), [symmetry](symmetry.md), or [social dynamics](broken-reference) of facial expressions.&#x20;







Depending on the backend processor used, the columns of the data frame have different meanings. With 3DI and 3DI-Lite, they may represent global, non-interpretable facial deformations along 79 PCA directions if generated by `processor.fit()`. Alternatively, they can denote localized, interpretable facial motions, similar to Action Units, if generated by `processor.localized_expressions()`. The `format` field will inform you of their specific representation. Wiht OpenFace (coming soon), they will correspond to Action Units.
